{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45973fd5-6259-4e03-9501-02ee96f3f870",
      "metadata": {
        "id": "45973fd5-6259-4e03-9501-02ee96f3f870"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "# Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9478ed9a",
      "metadata": {
        "id": "9478ed9a"
      },
      "source": [
        "# Introduction to TorchGeo\n",
        "\n",
        "_Written by: Adam J. Stewart_\n",
        "\n",
        "Now that we've seen the basics of PyTorch and the challenges of working with geospatial data, let's see how TorchGeo addresses these challenges."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f10e9f",
      "metadata": {
        "id": "34f10e9f"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First, we install TorchGeo and all of its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "019092f0",
      "metadata": {
        "id": "019092f0",
        "outputId": "4bd9b275-e0c3-419c-e249-bc7ed7566491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchgeo\n",
            "  Downloading torchgeo-0.6.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.8.0)\n",
            "Collecting fiona>=1.8.21 (from torchgeo)\n",
            "  Downloading fiona-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia>=0.7.3 (from torchgeo)\n",
            "  Downloading kornia-0.7.4-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting lightly!=1.4.26,>=1.4.5 (from torchgeo)\n",
            "  Downloading lightly-1.5.15-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting lightning!=2.3.*,>=2 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.2.2)\n",
            "Requirement already satisfied: pillow>=8.4 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (11.0.0)\n",
            "Requirement already satisfied: pyproj>=3.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.7.0)\n",
            "Collecting rasterio<1.4,>=1.3 (from torchgeo)\n",
            "  Downloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting rtree>=1 (from torchgeo)\n",
            "  Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting segmentation-models-pytorch>=0.2 (from torchgeo)\n",
            "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.0.6)\n",
            "Requirement already satisfied: timm>=0.4.12 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.0.12)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.5.1+cu121)\n",
            "Collecting torchmetrics>=0.10 (from torchgeo)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torchvision>=0.14 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.20.1+cu121)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->torchgeo) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->torchgeo) (2024.8.30)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.21->torchgeo) (8.1.7)\n",
            "Collecting click-plugins>=1.0 (from fiona>=1.8.21->torchgeo)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona>=1.8.21->torchgeo)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia>=0.7.3->torchgeo)\n",
            "  Downloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia>=0.7.3->torchgeo) (24.2)\n",
            "Collecting hydra-core>=1.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (4.66.6)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.10.3)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.2.3)\n",
            "Collecting aenum>=3.1.11 (from lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (4.12.2)\n",
            "Collecting bitsandbytes<1.0,>=0.42.0 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting jsonargparse<5.0,>=4.27.7 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading jsonargparse-4.34.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting omegaconf<3.0,>=2.2.3 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (13.9.4)\n",
            "Collecting tensorboardX<3.0,>=2.2 (from lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->torchgeo) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->torchgeo) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->torchgeo) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->torchgeo) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->torchgeo) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.3->torchgeo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.3->torchgeo) (2024.2)\n",
            "Collecting affine (from rasterio<1.4,>=1.3->torchgeo)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting snuggs>=1.4.1 (from rasterio<1.4,>=1.3->torchgeo)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio<1.4,>=1.3->torchgeo) (75.1.0)\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.26.3)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm>=0.4.12 (from torchgeo)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.4.12->torchgeo) (0.4.5)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch>=0.2->torchgeo)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->torchgeo) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->torchgeo) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->torchgeo) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->torchgeo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->torchgeo) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (3.11.9)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly!=1.4.26,>=1.4.5->torchgeo)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo)\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly!=1.4.26,>=1.4.5->torchgeo) (3.10)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2.18.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (4.25.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->torchgeo) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,>=2->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (1.18.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (0.1.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,>=2->torchgeo) (6.4.5)\n",
            "Downloading torchgeo-0.6.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.4-py2.py3-none-any.whl (899 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.4/899.4 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.15-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.1/845.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (543 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.34.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels, antlr4-python3-runtime\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=974e0e15f350336953d73ca9389981131b8e6829c0247bc198ff1e07c061ffda\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=aa4d6d6adafd897d1ee45cd38d5816413f17d489ee98d4d50a25ec5348da41f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=2c9fed956e5cbccc6786a39fd5b5f4b0d58f278c1fc68fa9e0c9c9c91267585f\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built efficientnet-pytorch pretrainedmodels antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, typeshed-client, tensorboardX, snuggs, rtree, omegaconf, munch, lightning-utilities, lightly_utils, kornia-rs, jsonargparse, cligj, click-plugins, affine, rasterio, hydra-core, fiona, torchmetrics, kornia, efficientnet-pytorch, bitsandbytes, timm, pretrainedmodels, segmentation-models-pytorch, pytorch_lightning, lightning, lightly, torchgeo\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.12\n",
            "    Uninstalling timm-1.0.12:\n",
            "      Successfully uninstalled timm-1.0.12\n",
            "Successfully installed aenum-3.1.15 affine-2.4.0 antlr4-python3-runtime-4.9.3 bitsandbytes-0.45.0 click-plugins-1.1.1 cligj-0.7.2 efficientnet-pytorch-0.7.1 fiona-1.10.1 hydra-core-1.3.2 jsonargparse-4.34.1 kornia-0.7.4 kornia-rs-0.1.7 lightly-1.5.15 lightly_utils-0.0.2 lightning-2.4.0 lightning-utilities-0.11.9 munch-4.0.0 omegaconf-2.3.0 pretrainedmodels-0.7.4 pytorch_lightning-2.4.0 rasterio-1.3.11 rtree-1.3.0 segmentation-models-pytorch-0.3.4 snuggs-1.4.7 tensorboardX-2.6.2.2 timm-0.9.7 torchgeo-0.6.1 torchmetrics-1.6.0 typeshed-client-2.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "0fa325ced5314827bce2aab78df11530"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install torchgeo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db9f791",
      "metadata": {
        "id": "4db9f791"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Next, we import TorchGeo and any other libraries we need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3d92b0f1",
      "metadata": {
        "id": "3d92b0f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchgeo.datasets import CDL, BoundingBox, Landsat7, Landsat8, stack_samples\n",
        "from torchgeo.datasets.utils import download_and_extract_archive\n",
        "from torchgeo.samplers import GridGeoSampler, RandomGeoSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b813beba-62ad-430c-96e5-1d81bef1e244",
      "metadata": {
        "id": "b813beba-62ad-430c-96e5-1d81bef1e244"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "Let's start with a common task in geospatial machine learning to motivate us: land cover mapping. Imagine you have a collection of imagery and a land cover layer or *mask* you would like to learn to predict. In machine learning, this pixelwise classification process is referred to as *semantic segmentation*.\n",
        "\n",
        "More concretely, imagine you would like to combine a set of Landsat 7 and 8 scenes with the Cropland Data Layer (CDL). This presents a number of challenges for a typical machine learning pipeline:\n",
        "\n",
        "* We may have hundreds of partially overlapping Landsat images that need to be mosaiced together\n",
        "* We have a single CDL mask covering the entire continental US\n",
        "* Neither the Landsat input or CDL output will have the same geospatial bounds\n",
        "* Landsat is multispectral, and may have a different resolution for each spectral band\n",
        "* Landsat 7 and 8 have a different number of spectral bands\n",
        "* Landsat and CDL may have a differerent CRS\n",
        "* Every single Landsat file may be in a different CRS (e.g., multiple UTM zones)\n",
        "* We may have multiple years of input and output data, and need to ensure matching time spans\n",
        "\n",
        "We can't have a dataset of length 1, and it isn't obvious what to do when the number, bounds, and size of input images differ from the output masks. Furthermore, each image is far too large to pass to a neural network.\n",
        "\n",
        "Traditionally, people either performed classification on a single pixel at a time or curated their own benchmark dataset. This works fine for training, but isn't really useful for inference. What we would really like to be able to do is sample small pixel-aligned pairs of input images and output masks from the region of overlap between both datasets. This exact situation is illustrated in the following figure:\n",
        "\n",
        "![Landsat CDL intersection](https://github.com/microsoft/torchgeo/blob/main/images/geodataset.png?raw=true)\n",
        "\n",
        "Now, let's see what features TorchGeo has to support this kind of use case."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41119706-0722-4fd0-85a7-787bb12bbab8",
      "metadata": {
        "id": "41119706-0722-4fd0-85a7-787bb12bbab8"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Geospatial data comes in a wide variety of formats. TorchGeo has two separate classes of datasets to deal with this dataset diversity:\n",
        "\n",
        "* `NonGeoDataset`: for curated benchmark datasets, where geospatial metadata is either missing or unnecessary\n",
        "* `GeoDataset`: for uncurated raster and vector data layers, where geospatial metadata is critical for merging datasets\n",
        "\n",
        "We have already seen the former in the Introduction to PyTorch tutorial, as `EuroSAT100` is a subclass of `NonGeoDataset`. In this tutorial, we will focus on the latter and its advantages for working with uncurated data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "914b39c6-3373-4ae8-b9ea-d377e73e9fbe",
      "metadata": {
        "id": "914b39c6-3373-4ae8-b9ea-d377e73e9fbe"
      },
      "source": [
        "### Landsat\n",
        "\n",
        "First, let's start with our Landsat imagery. We will download a couple of Landsat 7 and 8 scenes, then pass them to builtin TorchGeo datasets for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48d2a61d-16bb-4809-9da0-3bd369bff070",
      "metadata": {
        "id": "48d2a61d-16bb-4809-9da0-3bd369bff070",
        "outputId": "f649abc4-8b3e-42a2-8805-11b28ee0068f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://cdn-lfs-us-1.hf.co/repos/2d/f0/2df0bcf077cc4b52176ffd22a36ca59bc791d861935cc6c597aaf3137dd40ccc/f8553b0c81deadb9bd56d0e55445d1c2f030429bd5fdc6519274abba02bce774?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27LE07_L2SP_022032_20230725_20230820_02_T1.tar.gz%3B+filename%3D%22LE07_L2SP_022032_20230725_20230820_02_T1.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1733947994&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzk0Nzk5NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJkL2YwLzJkZjBiY2YwNzdjYzRiNTIxNzZmZmQyMmEzNmNhNTliYzc5MWQ4NjE5MzVjYzZjNTk3YWFmMzEzN2RkNDBjY2MvZjg1NTNiMGM4MWRlYWRiOWJkNTZkMGU1NTQ0NWQxYzJmMDMwNDI5YmQ1ZmRjNjUxOTI3NGFiYmEwMmJjZTc3ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=pJInRVUXn28I5wvqmG6%7EKwCQ6rx0m9htMN%7ESYB1LgjgPxxKidlzrwR-zEKDIbD9yYGjJY4jAXzS6-d0b8zpIFmz4q-bl-mpEGV0w3NMfUZYwulAci8zi3mMNZ5KN7rwcYMwTDx0Eb8Z-tFWOFBk6FVvk52p%7Et1kgq9G%7EhAxzYZCFsB-2On66HU1c1b-XRGLNZ6Kx1DfOvgexnyKw7vjhKDwD6FjN4qxUII2FyAzNpZgP6gZcBwlVrSnKYW-eA9Hs-BYcH3RxshdYEMqljs-z1ierWnxwDp4VlMMb9vt1WT-wDSgRVeslBIOflBtdczkBwmzBvdQ-R5sTHOjE4ZWLnA__&Key-Pair-Id=K24J24Z295AEI9 to /tmp/landsat/LE07_L2SP_022032_20230725_20230820_02_T1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.80M/7.80M [00:00<00:00, 39.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/landsat/LE07_L2SP_022032_20230725_20230820_02_T1.tar.gz to /tmp/landsat\n",
            "Downloading https://cdn-lfs-us-1.hf.co/repos/2d/f0/2df0bcf077cc4b52176ffd22a36ca59bc791d861935cc6c597aaf3137dd40ccc/5ce14aec440832e791c98db7505912c2be487002894a12eb7d4169b270295ff6?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27LC08_L2SP_023032_20230831_20230911_02_T1.tar.gz%3B+filename%3D%22LC08_L2SP_023032_20230831_20230911_02_T1.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1733947670&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzk0NzY3MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJkL2YwLzJkZjBiY2YwNzdjYzRiNTIxNzZmZmQyMmEzNmNhNTliYzc5MWQ4NjE5MzVjYzZjNTk3YWFmMzEzN2RkNDBjY2MvNWNlMTRhZWM0NDA4MzJlNzkxYzk4ZGI3NTA1OTEyYzJiZTQ4NzAwMjg5NGExMmViN2Q0MTY5YjI3MDI5NWZmNj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Jggr-sAgVVR6-IWbCe-zqnZLsDiCbz4osuMF%7Ej4NIL4XcjC4n6wbEUg-eTNGCnlvcbzrhc9oN04HZ8BGzuHmg5oWI0L0v-bdClP2U-pflZt90sujfH47IuWhoZEw22eA-UvG8wBwXZeCM6PADE3txITEcmwmgPjYbXPIhjZ-rHslNL0YrcIwXeTN1Cyi4ENzO7gOpidQGzcnzqIxFzRZibJC%7EDfqfGqNkbo20lvpGAgILVjyrSiLAdE9WEJBC1wLZCkyTKbGGxsrMcq6956An9MlMhyA%7EGpMDxLAVyBdxctCtU3xch-Cr1J9KZXSNoq%7E%7EAxqVGqalLrxxvMqDEa8yQ__&Key-Pair-Id=K24J24Z295AEI9 to /tmp/landsat/LC08_L2SP_023032_20230831_20230911_02_T1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.4M/11.4M [00:00<00:00, 36.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/landsat/LC08_L2SP_023032_20230831_20230911_02_T1.tar.gz to /tmp/landsat\n",
            "Landsat7 Dataset\n",
            "    type: GeoDataset\n",
            "    bbox: BoundingBox(minx=919035.8962764405, maxx=951840.0990326208, miny=4456195.4346259395, maxy=4488999.63738212, mint=1690243200.0, maxt=1690329599.999999)\n",
            "    size: 1\n",
            "Landsat8 Dataset\n",
            "    type: GeoDataset\n",
            "    bbox: BoundingBox(minx=410000.0, maxx=440720.0, miny=4445000.0, maxy=4475720.0, mint=1693440000.0, maxt=1693526399.999999)\n",
            "    size: 1\n",
            "EPSG:32615\n",
            "EPSG:32616\n"
          ]
        }
      ],
      "source": [
        "landsat_root = os.path.join(tempfile.gettempdir(), 'landsat')\n",
        "\n",
        "url = 'https://hf.co/datasets/torchgeo/tutorials/resolve/ff30b729e3cbf906148d69a4441cc68023898924/'\n",
        "landsat7_url = url + 'LE07_L2SP_022032_20230725_20230820_02_T1.tar.gz'\n",
        "landsat8_url = url + 'LC08_L2SP_023032_20230831_20230911_02_T1.tar.gz'\n",
        "\n",
        "download_and_extract_archive(landsat7_url, landsat_root)\n",
        "download_and_extract_archive(landsat8_url, landsat_root)\n",
        "\n",
        "landsat7_bands = ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n",
        "landsat8_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
        "\n",
        "landsat7 = Landsat7(paths=landsat_root, bands=landsat7_bands)\n",
        "landsat8 = Landsat8(paths=landsat_root, bands=landsat8_bands)\n",
        "\n",
        "print(landsat7)\n",
        "print(landsat8)\n",
        "\n",
        "print(landsat7.crs)\n",
        "print(landsat8.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce12838a-1010-46cb-bcca-6379f9e327ac",
      "metadata": {
        "id": "ce12838a-1010-46cb-bcca-6379f9e327ac"
      },
      "source": [
        "The following details are worth noting:\n",
        "\n",
        "* We ignore the \"coastal blue\" band of Landsat 8 because it does not exist in Landsat 7\n",
        "* Even though all files are stored in the same directory, the datasets know which files to include\n",
        "* `paths` can be a directory to recursively search, a list of local files, or even a list of remote cloud assets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51c5df2-5543-41ae-a9cf-254e29b6bdfd",
      "metadata": {
        "id": "a51c5df2-5543-41ae-a9cf-254e29b6bdfd"
      },
      "source": [
        "### CDL\n",
        "\n",
        "Next, let's do the same for the CDL dataset. We are using a smaller cropped version of this dataset to make the download faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "909d233b-b212-48f1-b910-3065f8fcf083",
      "metadata": {
        "id": "909d233b-b212-48f1-b910-3065f8fcf083",
        "outputId": "b4f23bfd-e5ad-4b99-dbf6-591774f2d408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://cdn-lfs-us-1.hf.co/repos/2d/f0/2df0bcf077cc4b52176ffd22a36ca59bc791d861935cc6c597aaf3137dd40ccc/abeecc4daa95d206364b3b6deee780f0ebe8e25e23f317ca1cdaff2c262ac101?response-content-disposition=inline%3B+filename*%3DUTF-8%27%272023_30m_cdls.zip%3B+filename%3D%222023_30m_cdls.zip%22%3B&response-content-type=application%2Fzip&Expires=1733948243&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzk0ODI0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJkL2YwLzJkZjBiY2YwNzdjYzRiNTIxNzZmZmQyMmEzNmNhNTliYzc5MWQ4NjE5MzVjYzZjNTk3YWFmMzEzN2RkNDBjY2MvYWJlZWNjNGRhYTk1ZDIwNjM2NGIzYjZkZWVlNzgwZjBlYmU4ZTI1ZTIzZjMxN2NhMWNkYWZmMmMyNjJhYzEwMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=RA8QDWXUGjSlPW5X%7ErBIOUGaFZGFsw%7Eqt2beZ01POucOMU77dgjMxYTxohIGaGomu5jGGqpxq574P3xkHM4zYfiQe21rV8FcLHvrl9BDalXqXrbg1l6f3T6wYBc7LXoifeVQxUa9fuM%7ExB5Egk1IZ6DbPtDF4Z%7ExbzQNRiak0TgbUURC%7EaaLty9CWIyrQHEikxIQGkaTBsUiXIHS30vXx5ybnTWQRTj90dLoFCGg9OaLFFml7hYjgLaqVVhIhgnUAC%7E41FvhXna1O5r28oRFUXNkJpMUV805GYEgP5XRedy8VlDUTLGsMHRYy93lfT5ton2NnIsBfy5FW-WyqN8O8w__&Key-Pair-Id=K24J24Z295AEI9 to /tmp/cdl/2023_30m_cdls.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 139k/139k [00:00<00:00, 12.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /tmp/cdl/2023_30m_cdls.zip to /tmp/cdl\n",
            "CDL Dataset\n",
            "    type: GeoDataset\n",
            "    bbox: BoundingBox(minx=667000.0, maxx=697720.0, miny=1931000.0, maxy=1961720.0, mint=1672531200.0, maxt=1704067199.999999)\n",
            "    size: 1\n",
            "EPSG:5070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "cdl_root = os.path.join(tempfile.gettempdir(), 'cdl')\n",
        "\n",
        "cdl_url = url + '2023_30m_cdls.zip'\n",
        "\n",
        "download_and_extract_archive(cdl_url, cdl_root)\n",
        "\n",
        "cdl = CDL(paths=cdl_root)\n",
        "\n",
        "print(cdl)\n",
        "print(cdl.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "571a6512-494f-401a-bf2f-599f28b2fad5",
      "metadata": {
        "id": "571a6512-494f-401a-bf2f-599f28b2fad5"
      },
      "source": [
        "Again, the following details are worth noting:\n",
        "\n",
        "* We could actually ask the `CDL` dataset to download our data for us by adding `download=True`\n",
        "* All datasets have different spatial extents\n",
        "* All datasets have different CRSs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a15b938-3277-46bc-86e4-a5d7f57e838a",
      "metadata": {
        "id": "4a15b938-3277-46bc-86e4-a5d7f57e838a"
      },
      "source": [
        "### Composing datasets\n",
        "\n",
        "We would like to be able to intelligently combine all three datasets in order to train a land cover mapping model. This requires us to create a virtual mosaic of all Landsat scenes, regardless of overlap. This can be done by taking the *union* of both datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b5adace-d7c9-4c27-9e53-ae532b081046",
      "metadata": {
        "id": "4b5adace-d7c9-4c27-9e53-ae532b081046"
      },
      "outputs": [],
      "source": [
        "landsat = landsat7 | landsat8\n",
        "print(landsat)\n",
        "print(landsat.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddac6f18-36de-4241-a150-0ee50d0f40dd",
      "metadata": {
        "id": "ddac6f18-36de-4241-a150-0ee50d0f40dd"
      },
      "source": [
        "Similarly, we only want to sample from locations with both input imagery and output masks, not locations with only one or the other. We can achieve this by taking the *intersection* of both datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd9f067-0e00-47ac-8bc1-6e7cd9e41e4d",
      "metadata": {
        "id": "6dd9f067-0e00-47ac-8bc1-6e7cd9e41e4d"
      },
      "outputs": [],
      "source": [
        "dataset = landsat & cdl\n",
        "print(dataset)\n",
        "print(dataset.crs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d2afbe-aab8-415e-a0df-fdb0d5209a49",
      "metadata": {
        "id": "48d2afbe-aab8-415e-a0df-fdb0d5209a49"
      },
      "source": [
        "Note that all datasets now have the same CRS. When you run this code, you should notice it happen very quickly. TorchGeo hasn't actually created a mosaic yet or reprojected anything, it will do this on the fly for us."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4df7ee26-2c11-4e70-b113-e633fbbc2cd9",
      "metadata": {
        "id": "4df7ee26-2c11-4e70-b113-e633fbbc2cd9"
      },
      "source": [
        "### Spatiotemporal indexing\n",
        "\n",
        "How did we do this? TorchGeo uses a data structure called an *R-tree* to store the spatiotemporal bounding box of every file in the dataset.\n",
        "\n",
        "![R-tree](https://raw.githubusercontent.com/davidmoten/davidmoten.github.io/master/resources/rtree-3d/plot2.png)\n",
        "\n",
        "TorchGeo extracts the spatial bounding box from the metadata of each file, and the timestamp from the filename. This geospatial and geotemporal metadata allows us to efficiently compute the intersection or union of two datasets. It also lets us quickly retrieve an image and corresponding mask for a particular location in space and time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3992c571-0a6f-4d28-a2dc-e5915c00901e",
      "metadata": {
        "id": "3992c571-0a6f-4d28-a2dc-e5915c00901e"
      },
      "outputs": [],
      "source": [
        "size = 256\n",
        "\n",
        "xmin = 925000\n",
        "xmax = xmin + size * 30\n",
        "ymin = 4470000\n",
        "ymax = ymin + size * 30\n",
        "tmin = datetime(2023, 1, 1).timestamp()\n",
        "tmax = datetime(2023, 12, 31).timestamp()\n",
        "\n",
        "bbox = BoundingBox(xmin, xmax, ymin, ymax, tmin, tmax)\n",
        "sample = dataset[bbox]\n",
        "\n",
        "landsat8.plot(sample)\n",
        "cdl.plot(sample)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc591543-6d74-47b3-8c24-feada66d0a38",
      "metadata": {
        "id": "bc591543-6d74-47b3-8c24-feada66d0a38"
      },
      "source": [
        "TorchGeo uses *windowed-reading* to only read the blocks of memory needed to load a small patch from a large raster tile. It also automatically reprojects all data to the same CRS and resolution (from the first dataset). This can be controlled by explicitly passing `crs` or `res` to the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2e4221e-dfb7-4966-96a6-e52400ae266c",
      "metadata": {
        "id": "e2e4221e-dfb7-4966-96a6-e52400ae266c"
      },
      "source": [
        "## Samplers\n",
        "\n",
        "The above `BoundingBox` makes it easy to index into complex datasets consisting of hundreds of files. However, it is a bit cumbersome to manually construct these queries every time, especially if we want thousands or even millions of bounding boxes. Luckily, TorchGeo provides a `GeoSampler` class to construct these for us."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47a7423d-32a9-40ae-be62-d54805835b19",
      "metadata": {
        "id": "47a7423d-32a9-40ae-be62-d54805835b19"
      },
      "source": [
        "### Random sampling\n",
        "\n",
        "Usually, at training time, we want the largest possible dataset we can muster. For curated benchmark datasets like `EuroSAT100`, we achieved this by applying data augmentation to artificially inflate the size and diversity of our dataset. For `GeoDataset` objects, we can achieve this using random sampling. It doesn't matter if two or more of our images have partial overlap, as long as they bring unique pixels that help our model learn.\n",
        "\n",
        "TorchGeo provides a `RandomGeoSampler` to achieve this. We just tell the sampler how large we want each image patch to be (in pixel coordinates or CRS units) and, optionally, the number of image patches per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a60164-aa88-4773-a38f-d40960f4bfb2",
      "metadata": {
        "id": "36a60164-aa88-4773-a38f-d40960f4bfb2"
      },
      "outputs": [],
      "source": [
        "train_sampler = RandomGeoSampler(dataset, size=size, length=1000)\n",
        "next(iter(train_sampler))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d35b26-edae-46dc-b232-878421faa84d",
      "metadata": {
        "id": "b6d35b26-edae-46dc-b232-878421faa84d"
      },
      "source": [
        "### Gridded sampling\n",
        "\n",
        "At evaluation time, this actually becomes a problem. We want to make sure we aren't making multiple predictions for the same location. We also want to make sure we don't miss any locations. To achieve this, TorchGeo also provides a `GridGeoSampler`. We can tell the sampler the size of each image patch and the stride of our sliding window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33340c1a-756f-4ffe-ae3d-c2307fc98d07",
      "metadata": {
        "id": "33340c1a-756f-4ffe-ae3d-c2307fc98d07"
      },
      "outputs": [],
      "source": [
        "test_sampler = GridGeoSampler(dataset, size=size, stride=size)\n",
        "next(iter(test_sampler))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9806919-6520-4da6-9eb3-3e1e6a10498e",
      "metadata": {
        "id": "b9806919-6520-4da6-9eb3-3e1e6a10498e"
      },
      "source": [
        "## Data Loaders\n",
        "\n",
        "All of these abstractions (`GeoDataset` and `GeoSampler`) are fully compatible with all of the rest of PyTorch. We can simply pass them to a data loader like below. Note that we also need the `stack_samples` collation function to convert a list of samples to a mini-batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd44d29d-b7c0-4617-bb94-d41a14e8f54a",
      "metadata": {
        "id": "fd44d29d-b7c0-4617-bb94-d41a14e8f54a"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    dataset, batch_size=128, sampler=train_sampler, collate_fn=stack_samples\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    dataset, batch_size=128, sampler=test_sampler, collate_fn=stack_samples\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e46e8453-df25-4265-a85b-75dce7dea047",
      "metadata": {
        "id": "e46e8453-df25-4265-a85b-75dce7dea047"
      },
      "source": [
        "Now that we have working data loaders, we can copy-n-paste our training code from the Introduction to PyTorch tutorial. We only need to change our model to one designed for semantic segmentation, such as a U-Net. Every other line of code would be identical to how you would do this in your normal PyTorch workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3acc64e-8dc0-46b4-a677-ecb9723d4f56",
      "metadata": {
        "id": "a3acc64e-8dc0-46b4-a677-ecb9723d4f56"
      },
      "source": [
        "## Additional Reading\n",
        "\n",
        "TorchGeo has plenty of other tutorials and documentation. If you would like to get more insight into the design of TorchGeo, the following external resources are also helpful:\n",
        "\n",
        "* [TorchGeo: Deep Learning With Geospatial Data](https://arxiv.org/abs/2111.08872)\n",
        "* [Geospatial deep learning with TorchGeo](https://pytorch.org/blog/geospatial-deep-learning-with-torchgeo/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "getting_started.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "execution": {
      "timeout": 1200
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}